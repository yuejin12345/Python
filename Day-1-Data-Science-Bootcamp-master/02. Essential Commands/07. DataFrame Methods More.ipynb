{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. DataFrame Methods More\n",
    "\n",
    "### Objectives\n",
    "\n",
    "+ Understand how to use the following methods to handle missing data: **`isna`**, **`notna`**, **`fillna`**, **`dropna`**\n",
    "+ Sort values and the index with **`sort_values`** and **`sort_index`**\n",
    "+ Find the index of the max and min with **`idxmax`** and **`idxmin`**\n",
    "+ Renaming column names with **`rename`**\n",
    "+ Dropping columns with **`drop`**\n",
    "+ Explore uniqueness with **`nunique`** and **`drop_duplicates`**\n",
    "+ Add new columns to a  DataFrame\n",
    "+ Operate with two Series at a time\n",
    "+ Methods DataFrames do not have - **`str`**, **`dt`**, **`unique`**, **`value_counts`**\n",
    "+ Use the function **`pd.to_numeric`** to coerce string columns to numeric data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook covers many more common DataFrame methods. Again, these are the most common and fundamental methods that give you all the power to complete any data analysis. All of these methods are also found in Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = pd.read_csv('../data/college.csv', index_col='instnm')\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for handling missing values\n",
    "Pandas provides the following methods to handle missing values:\n",
    "\n",
    "* **`isna`** - Returns a Series of booleans based on whether each value is missing or not\n",
    "* **`notna`** - Exact opposite of **`isna`**\n",
    "* **`fillna`** - fills missing values in a variety of ways\n",
    "* **`dropna`** - Drops the missing values from the Series\n",
    "\n",
    "### Finding the number of missing values in each column\n",
    "Pandas gives us a direct way to find the number of non-missing values in each column with the **`count`** method. To find the number of missing values we will need to call the **`isna`** method to turn each value into a boolean and then sum each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of non-missing values per column\n",
    "college.count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.isna().sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the percentage of missing values by calling the mean method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fillna`** and **`dropna`** will be covered in a notebook specific to handling missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting with `sort_values`\n",
    "The **`sort_values`** DataFrame method sorts the DataFrame by one or more columns. Pass the **`by`** parameter a column name or list of column names to sort. By default the sorting takes place in ascending manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.sort_values(by='city').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simultaneously sort two or more columns\n",
    "Sort by any number of columns by passing a list of their names to the **`by`** parameter. The sort happens by going left to right through the columns. For instance, the following sorts all the colleges by state, and then within each state, sorts by undergraduate population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ugds_sort = college.sort_values(by=['stabbr', 'ugds'])\n",
    "state_ugds_sort[['stabbr', 'ugds']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select just the state of Oklahoma to verify that it too is sorted by undergraduate population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = state_ugds_sort['stabbr'] == 'OK'\n",
    "cols = ['stabbr', 'ugds']\n",
    "state_ugds_sort.loc[filt, cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort multiple columns in different directions\n",
    "The **`ascending`** parameter may be passed a list of booleans that correspond to the list of column names in the **`by`** parameter. The following sorts by state and then by undergraduate population from greatest to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.sort_values(by=cols, ascending=[True, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by the Index\n",
    "The DataFrame may be sorted by its index with the **`sort_index`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.sort_index(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the index of the maximum of each column with `idxmax`\n",
    "The **`idxmax`** method is quite powerful and returns the index value for the maximum of each column. It does not work with string columns. The following selects just the numeric columns and then calls the **`idxmax`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.select_dtypes('number').idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results\n",
    "A Series is returned with the old column names in the index and the maximum index as the values. For instance, the school with the highest average SAT Math scores is California Institute of Technology. The school with the highest percentage of undergraduate population above 25 years of age is Dongguk University-Los Angeles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns\n",
    "The **`drop`** method drops columns passed to the **`columns`** parameter as either a string or a list of strings. Let's see examples of dropping a single column and then multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.drop(columns='city').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['city', 'stabbr', 'satvrmid']\n",
    "college.drop(columns=cols).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "The **`rename`** columns method is used to rename columns. Pass a dictionary to the **`columns`** parameter with keys equal to the old column name and values equal to the new column name.\n",
    "\n",
    "The college dataset has lots of columns with abbreviations that are not immediately recognized. We replace a couple of these columns with more explicit names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.rename(columns={'hbcu': 'Historically Black Colleges and Universities',\n",
    "                       'stabbr': 'State Abbreviation'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `nunique` method\n",
    "The **`nunique`** method returns the number of unique values for each column. It defaults to ignoring missing values. It technically is an aggregation method as it returns a single value for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a new column to the DataFrame\n",
    "A new column may be added to a DataFrame using similar syntax to selecting a single column with the brackets. The general syntax will look like the following:\n",
    "\n",
    "```\n",
    ">>> df['new_column'] = <some expression>\n",
    "```\n",
    "\n",
    "Let's add the two SAT columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['sat_total'] = college['satmtmid'] + college['satvrmid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important methods Available only to Series and not DataFrames\n",
    "There are are more than a few methods that are available only to Series objects, but the following are the most important.\n",
    "\n",
    "### No `str` or `dt` accessor\n",
    "DataFrames have no special methods just for strings or datetimes. There is no **`str`** or **`dt`** accessor. You can only use these accessors on Series objects. This usually means that you will select a column as a Series first.\n",
    "\n",
    "### No `unique` or `value_counts`\n",
    "Both **`unique`** and **`value_counts`** are only available to Series as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/college_data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Use the college dataset for the first few problems. You may want/need to read the 'Extra' section below first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Find the number of missing values for each row.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">What percentage of rows have more than 5 missing values?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">How many total missing values are there in the entire DataFrame?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Several of the columns contain binary data (are either 0 or 1). Can you identify the names of these columns?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">Read the documentation on the `dropna` method. What is the shape of the returned DataFrame when called with the defaults? Call it again except only drop rows if `ugds` is missing. What is the shape of this DataFrame?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "<span  style=\"color:green; font-size:16px\">Create a new boolean column in the college named 'Verbal Higher' that is True for every college that has a verbal than math SAT score. Find the mean of this new column. Why does this number look suspiciously low?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "<span  style=\"color:green; font-size:16px\">Find the real percentage of schools with higher verbal than math SAT scores.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the flights dataset with the remainder of the problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8\n",
    "<span  style=\"color:green; font-size:16px\">Read in the flights dataset (`flights.csv`) and call `dropna` with the defaults. What kind of DataFrame was returned? Why? Verify that each row has at least one missing value.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9\n",
    "<span  style=\"color:green; font-size:16px\">Read the `dropna` docs again and keep rows that have at least 28 non-missing values. Verify the results.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10\n",
    "<span  style=\"color:green; font-size:16px\">Find the longest `arrival_delay` for every  airline for every month.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "More important material on DataFrame methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping duplicate rows with `drop_duplicates`\n",
    "The default call to the **`drop_duplicates`** method returns only unique rows of the DataFrame. It does not use the index value in its search for duplicates. If two or more row are duplicated, the first row is kept. \n",
    "\n",
    "Let's see if there are any duplicate rows in the college dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, there are some rows that have an exact duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates based on a subset of columns\n",
    "The **`drop_duplicates`** method gives you the **`subset`** parameter to check for duplicates within the columns passed to it. The following returns a single row for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.drop_duplicates(subset='stabbr').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.drop_duplicates(subset='stabbr').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data includes several territories and not just the 50 states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Selecting the school with the maximum SAT scores for each state\n",
    "Let's say we are interested in finding the school with the maximum total SAT score for each state. The dataset gives us the math and verbal SAT scores.\n",
    "\n",
    "First ensure that we have a column for the total SAT score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['sat_total'] = college['satmtmid'] + college['satvrmid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this column gets added to the end. Let's select just a subset of the college DataFrame so it is easier to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['stabbr', 'ugds', 'satmtmid', 'satvrmid', 'sat_total']\n",
    "total_sat = college[cols]\n",
    "total_sat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort data first\n",
    "If we sort by state and total SAT score we will get close to finding the schools with the best scores for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sat.sort_values(['stabbr', 'sat_total'], ascending=[True, False]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `drop_duplicates` to finish the problem\n",
    "We would like to keep the first for every state after the data has been sorted. The **`drop_duplicates`** method does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sat.sort_values(['stabbr', 'sat_total'], ascending=[True, False]) \\\n",
    "         .drop_duplicates(subset='stabbr').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-Study 2: Hidden String Columns\n",
    "When reading in data, a common misfortune is to have a column that you believe to be numeric to be a string. This happens when columns contain a mix of numeric and string data. By default, pandas leaves these columns as strings. This happened with the both the `MD_EARN_WNE_P10` (median earnings after 10 years of enrollment) and `GRAD_DEBT_MDN_SUPP` columns (median debt of completers).\n",
    "\n",
    "Visually inspecting the first few rows makes it appear that these columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['md_earn_wne_p10', 'grad_debt_mdn_supp']\n",
    "college[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But looking at their data types reveals that they are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college[cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output values as NumPy array\n",
    "To see that they are strings, you can output their values as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['md_earn_wne_p10'].values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean indexing to discover alphabetic strings\n",
    "It's very likely that alphabetic string data does appear in these columns. One way to reveal them is to use the string method **`isalpha`** which returns True if one of the characters is alphabetic. This boolean Series can be used to filter for just the alphabetic values.\n",
    "\n",
    "There is one tiny issue. There are also **`NaN`** values in this Series. - the **`isalpha`** method returns **`NaN`** and not False for them. For boolean indexing to work, we need all values of the filtering Series to be boolean. We use **`fillna`** to fill these values with False so that our boolean indexing works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings = college['md_earn_wne_p10']\n",
    "filt = earnings.str.isalpha().fillna(False)\n",
    "earnings[filt].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count all the alphabetic strings\n",
    "Let's use the **`value_counts`** method to see the count of all the different alphabetic strings found. The only alphabetic string is 'PrivacySuppressed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings[filt].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coercing to missing values\n",
    "We can still convert this column to a numeric by converting all the non-numeric strings to missing values. We have to use the pandas **function** **`to_numeric`**. It is accessed directly from **`pd`**. We must call it with **`errors`** set to the string **`coerce`**. This forces any non-numeric data to **`NaN`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_numeric = pd.to_numeric(earnings, errors='coerce')\n",
    "earnings_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the data type is now float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_numeric.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the columns\n",
    "Our DataFrame still has not been altered. Let's re-assign both columns to their new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college['md_earn_wne_p10'] = pd.to_numeric(college['md_earn_wne_p10'], errors='coerce')\n",
    "college['grad_debt_mdn_supp'] = pd.to_numeric(college['grad_debt_mdn_supp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the data types have been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
