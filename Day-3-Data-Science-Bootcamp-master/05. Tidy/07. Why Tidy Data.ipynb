{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Why Tidy Data\n",
    "\n",
    "### Summary\n",
    "\n",
    "+ Know why Tidy data works and where it works best\n",
    "\n",
    "### Resources\n",
    "+ Reading the Seaborn tutorial on [categorical data](http://seaborn.pydata.org/tutorial/categorical.html)\n",
    "\n",
    "### Introduction\n",
    "In this notebook we will see why tidy data is useful. Tidy data is supposed to make our lives easier by making aggregation, sorting, filtering, visualizing and applying machine learning easier.\n",
    "\n",
    "To test this idea, we will perform many different data analyses on both the tidy and original datasets to see how they differ. We will use the tidied My Brother's Keeper data from the case study.\n",
    "\n",
    "### Read in original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../data/tidy/my_brothers_keeper.csv')\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick to removing all percentages with `replace` method\n",
    "The **`replace`** method normally replaces a specific value with another. If you set the **`regex`** parameter to True, you can be very precise with what you replace. Here, we simply replace all the percentage signs with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df_original.replace('%', '', regex=True)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check our data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each column to numeric\n",
    "Unfortunately, the **`pd.to_numeric`** function only works on Series and not on entire DataFrames. The **`astype`** method can convert all columns to numeric but only if all of them are capable of being converted. Here, the race column will cause it to fail.\n",
    "\n",
    "### Apply `pd.to_numeric` to each column\n",
    "The **`apply`** method can apply a function to each column (as a Series) independently. We simply pass the function name as the first argument to the **`apply`**. You can pass additional parameters to that function (**`pd.to_numeric`** in our case) by naming them as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df_original.apply(pd.to_numeric, errors='ignore')\n",
    "df_original.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `apply` is just a for loop\n",
    "The **`apply`** is just a replacement for a **`for`** loop. It simply applies the passed function to each column. It does the exact same thing as the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_original.columns:\n",
    "    df_original[col] = pd.to_numeric(df_original[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to our Comparison with Tidy Data\n",
    "Let's read in our tidy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = pd.read_csv('../data/tidy/mbk_tidy.csv')\n",
    "df_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison #1\n",
    "For our first comparison between tidy and messy data we will filter for the race **`Black`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "filt = df_original['Race'] == 'Black'\n",
    "df_original[filt].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy\n",
    "filt = df_tidy['Race'] == 'Black'\n",
    "df_tidy[filt].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for comparison #1\n",
    "Since the messy dataset had the race in a single column, the code is identical. The messy dataset might actually be preferable for readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison #2\n",
    "Filter for black males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "male_columns = df_original.columns.str.contains('of male')\n",
    "filt = df_original['Race'] == 'Black'\n",
    "\n",
    "df_original.loc[filt, male_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy\n",
    "filt = (df_tidy['Race'] == 'Black') & (df_tidy['Gender'] == 'male')\n",
    "df_tidy[filt].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for comparison #2\n",
    "This filter is a huge win for tidy data. The filtering is much more straightforward and the entire dataset is returned instead of just two columns. The birth rate is also returned specifically for males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison #3\n",
    "Find the average percentage women for all races for each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "cols = ['Distribution of female children born to women ages 18-19',\n",
    "       'Distribution of female children born to women ages 20-24']\n",
    "df_original[cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy\n",
    "filt = df_tidy['Gender'] == 'female'\n",
    "df_tidy[filt].groupby('Age Group').agg({'Gender Percent': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for comparison #3\n",
    "Since the messy data has both female and male observations in the same line, no groupby is needed. They are both fairly straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison #4\n",
    "Which gender has the highest average birth rate for each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "age_18_19_female = (df_original['Rate of birth to women ages 18-19'] / 100 * \n",
    "                 df_original['Distribution of female children born to women ages 18-19']).mean()\n",
    "\n",
    "age_20_24_female = (df_original['Rate of birth to women ages 20-24'] / 100 * \n",
    "                     df_original['Distribution of female children born to women ages 20-24']).mean()\n",
    "\n",
    "age_18_19_male = (df_original['Rate of birth to women ages 18-19'] / 100 * \n",
    "                 df_original['Distribution of male children born to women ages 18-19']).mean()\n",
    "\n",
    "age_20_24_male = (df_original['Rate of birth to women ages 20-24'] / 100 * \n",
    "                     df_original['Distribution of male children born to women ages 20-24']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_18_19_female, age_20_24_female, age_18_19_male, age_20_24_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy\n",
    "df_tidy.groupby(['Gender', 'Age Group'])['Birth Rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for comparison #4\n",
    "Tidy is a huge winner as the birth rate for each gender had been pre-calculated and the annoying long column names can be avoided.\n",
    "\n",
    "Can also use a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy.pivot_table(index='Age Group', columns='Gender', values='Birth Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison #5\n",
    "Which year, age group, race combination has the highest rate of births?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.sort_values('Rate of birth to women ages 18-19', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.sort_values('Rate of birth to women ages 20-24', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy.groupby(['Race', 'Year', 'Age Group'], as_index=False).agg({'Birth Rate':'sum'}) \\\n",
    "       .sort_values('Birth Rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for comparison #5\n",
    "The original data aggregates by all births, and is not broken down by gender. We need to sort by both birth rate columns to determine which age group is the highest.\n",
    "\n",
    "For tidy data, we need to group together race and year so that we can sum up the birth rates for both genders. We can then perform one sort to get our answer.\n",
    "\n",
    "## Visualization Advantage\n",
    "Huge advantages for tidy data come from plotting use the Seaborn library, which expects tidy data.\n",
    "\n",
    "The examples below only show tidy. The first plot shows the percentage of each gender per year by age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Year', \n",
    "            y='Gender Percent', \n",
    "            hue='Gender', \n",
    "            col='Age Group',\n",
    "            data=df_tidy, \n",
    "            kind='box', \n",
    "            height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Year', \n",
    "            y='Birth Rate', \n",
    "            hue='Race', \n",
    "            row = 'Gender', \n",
    "            col='Age Group', \n",
    "            kind='point',\n",
    "            data=df_tidy, \n",
    "            ci=0, \n",
    "            height=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating data into multiple tables (data normalization)\n",
    "Let's take a look at few rows from some visits to a doctor in the **`tidy/doctor_visits.csv`** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = pd.read_csv('../data/tidy/doctor_visits.csv')\n",
    "dv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The information is easy to read\n",
    "All the information presented in this table is easy to read. Any question that is asked about the visits can be quickly answered.\n",
    "\n",
    "### Yet, something is wrong, what is it?\n",
    "Although the table of data is sufficient to address our questions, it repeats much of the data and will not scale well as more patients come into the system. It will also be difficult to update historical data, such as if the patient's address changes or a clinic changes names.\n",
    "\n",
    "### A short intro into data normalization\n",
    "Modern databases attempt to reduce the amount of replication in the data by a process called **normalization**. It involves separating data into tables to minimize replication and increase data accuracy.\n",
    "\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Database_normalization):\n",
    "> Database Normalization, or simply normalization, is the process of organizing the columns (attributes) and tables (relations) of a relational database to reduce data redundancy and improve data integrity. Normalization is also the process of simplifying the design of a database so that it achieves the optimum structure. It reduces and eliminates redundant data. In normalization, data integrity is assured. It was first proposed by Dr. Edgar F. Codd, as an integral part of a relational model.\n",
    "\n",
    "There is much, much more to data normalization. The following example is just a brief overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which values are always the same for each visit?\n",
    "When looking through the table, you should notice that certain values will repeat for every single visit. For instance, the patient name, address, and birth date are going to be the same. There isn't a need to keep repeating all these values for every visit.\n",
    "\n",
    "### Separating patient values into a distinct table\n",
    "Let's select all the patient columns in a single DataFrame. The **`copy`** method is called to ensure that this is new DataFrame is a completely different DataFrame and not referring to the same data as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = dv[['patient_name', 'patient_address', 'patient_birthdate']]\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate rows\n",
    "There is no need to store duplicate values of each row. Let's keep only the unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = patient.drop_duplicates()\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a primary key to uniquely identify each row\n",
    "When we normalize our data, and separate it into new tables, an additional column is added to the table to uniquely identify each row. The unique value that identifies each row is called a **primary key**. Let's add a primary key to the patient table. Note: If you get the **`SettingWithCopyWarning`**, ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient['patient_id'] = np.arange(len(patient))\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange the columns so that `patient_id` is first\n",
    "It's best to always put the primary key as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'patient_name', 'patient_address', 'patient_birthdate']\n",
    "patient = patient[cols]\n",
    "patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We just created a dimension\n",
    "In database terminology, the patient table would be considered a **dimension**. Dimensions are things that exist in your data that are independent of any event taking place. They tend to be static and do not change often (such as your name or birth date.\n",
    "\n",
    "## Create tables for all the other dimensions\n",
    "There are several other dimensions in our original table. Let's create new dimension tables for each one of the following:\n",
    "* clinic\n",
    "* doctor\n",
    "* procedure\n",
    "\n",
    "We will select each of the columns unique to each dimension, drop the replicated rows and add a primary key as the first column to uniquely identify each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clinic_name', 'clinic_address']\n",
    "clinic = dv[cols].drop_duplicates()\n",
    "clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic['clinic_id'] = np.arange(len(clinic))\n",
    "clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['clinic_id', 'clinic_name', 'clinic_address']\n",
    "clinic = clinic[cols]\n",
    "clinic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['doctor_name', 'doctor_specialty']\n",
    "doctor = dv[cols].drop_duplicates()\n",
    "doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor['doctor_id'] = np.arange(len(doctor))\n",
    "doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['doctor_id', 'doctor_name', 'doctor_specialty']\n",
    "doctor = doctor[cols]\n",
    "doctor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Dimension\n",
    "Here, the primary key is already given to us with the procedure code. We will keep it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['procedure_code', 'procedure_name']\n",
    "procedure = dv[cols].drop_duplicates()\n",
    "procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing original data with primary keys\n",
    "We can now revisit our original DataFrame and replace all columns in each dimension with a single column, the primary key of that dimension.\n",
    "\n",
    "## Join original table to dimension tables\n",
    "To make the replacement, we will join our original table to each one of our dimension tables. The **`merge`** method joins tables together in Pandas. We can specify how the tables will join with the **`on`** parameter. We will join on all the non-primary key columns. Below, we join the **`patient`** table. The result is one extra column at the end of the DataFrame, the **`patient_id`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv.merge(patient, on=['patient_name', 'patient_address', 'patient_birthdate'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the dimension columns\n",
    "We can now drop all the original patient columns as the **`patient_id`** now refers to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.drop(columns=['patient_name', 'patient_address', 'patient_birthdate'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the other dimensions with primary key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doctor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.merge(doctor, on=['doctor_name', 'doctor_specialty'])\n",
    "dv_fact = dv_fact.drop(columns=['doctor_name', 'doctor_specialty'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.merge(clinic, on=['clinic_name', 'clinic_address'])\n",
    "dv_fact = dv_fact.drop(columns=['clinic_name', 'clinic_address'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Dimension\n",
    "Since the primary key is already in the table, we can just drop the **`procedure_name`** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_fact = dv_fact.drop(columns=['procedure_name'])\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange columns with foreign keys first\n",
    "When a primary key from table is found in another table, it is called a **foreign key**. Foreign keys can repeat in the table they are in. Primary keys, however, can never repeat in the tables they are in. This is a very important property. Foreign keys are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'clinic_id', 'doctor_id', \n",
    "        'procedure_code', 'visit_date', 'cost']\n",
    "dv_fact = dv_fact[cols]\n",
    "dv_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact Table\n",
    "This last DataFrame, **`dv_fact`** is called a **fact table** using database terminology. Fact tables hold the actual **events** or **transactions** that take place in a business. They hold the columns that are subject to change such as date and cost here. If we had data from a grocery store, our fact table would have columns like the number of items purchased, the cost of each item, and the type of payment used.  Fact tables have references to the static dimension tables through foreign keys.\n",
    "\n",
    "# Data Model Diagram\n",
    "The diagram of the **data model** or **entity-relationship diagram** is presented below. Data models show the logical relationships between the fact and dimension tables. This type of data model is called a **star schema** and one of the simplest designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/doctor_data_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [this simple Stack Overflow answer][1] for another description of fact and dimension tables.\n",
    "\n",
    "[1]: https://stackoverflow.com/a/33750545/3707607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset **`tidy/Impaired_Driving_Death_Rate.csv`**. Make a plot using seaborn comparing male to female drivers in 2012/2014.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset **`tidy/store_transactions.csv`**.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">Use the **`pd.read_excel`** function to read the **`tidy/genetic_engineered.xlsx`** and tidy it (very difficult).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
