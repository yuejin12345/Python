{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Checklist\n",
    "This notebook contains a checklist of many of the different things you can do during exploratory data analysis.\n",
    "\n",
    "## Develop your own Data Analysis Routine\n",
    "* Use this notebook as a starting point for developing your own data analysis routine. Ideally, you will create and continually modify this document so that it contains all the ideas and steps you usually take during an analysis.\n",
    "\n",
    "## Project Genesis\n",
    "These are some things to do at the genesis of your data analysis project\n",
    "* Create a folder in your file system to hold all your files for the analysis\n",
    "* Create a document or spreadsheet to store the names, titles, contact information and notes of all the people connected to your project\n",
    "* Have a mindset of a detective - you need to investigate your data in all possible ways\n",
    "* You can also think of yourself as making a documentary about the data. You will ultimately tell some story about it. Make it accurate and interesting.\n",
    "* Find and introduce yourself to all the people connected to your project\n",
    "* Connections to others is key to making your projects work. The more you are visible to others the more information will freely pass your way\n",
    "* Be aware of all the people that are directly and indirectly connected to your project. Meet all of them\n",
    " * Stakeholders\n",
    " * Domain Experts\n",
    " * Other data scientists\n",
    " * Database admins - data engineers\n",
    " * Solutions architects\n",
    " * Project managers\n",
    " * Web developers\n",
    " \n",
    "## Before Looking at Data\n",
    "Once you have been given access to data, in a text document or Jupyter notebook, answer the following questions:\n",
    "* What process generates this data?\n",
    "* Is it generated from industrial equipment, a website, internal software?\n",
    "* When was it created?\n",
    "* How often is it updated?\n",
    "* What database(if any) is it stored in?\n",
    "* Who are the admins of the database?\n",
    "* Can you view the schema?\n",
    "* What is the process that the raw data has gone through before it reached your hands? Has it already been pre-processed before it reaches you?\n",
    "* Is there a data dictionary describing every column?\n",
    "* What systems use the data?\n",
    "* Have their been previous data scientists working with this dataset?\n",
    "* How has data changed over time? Which columns have been added/subtracted? \n",
    "* Is data for some columns not being collected?\n",
    "\n",
    "## Subject Matter Research\n",
    "* Read articles, watch videos, talk to local subject matter experts before looking at data\n",
    "* Read articles/papers by academics who have already studied the field using statistical analysis\n",
    "\n",
    "## First Look at Data\n",
    "* Find data dictionary\n",
    "* Even if one exists, create a column to keep track of notes for each variable\n",
    "* Make sure your data dictionary has the column name, data type, and notes on each column\n",
    "* If the data comes from a relational database, ask to see the schema\n",
    "\n",
    "## Is the Data Tidy?\n",
    "* Data must be tidy before analysis starts.\n",
    "* Most data from relational databases will be tidy\n",
    "* Data from spreadsheets or scraped from pdfs or online might not be\n",
    "* Make sure you know whether each column is continuous or categorical (ordinal or nominal)\n",
    "* Rearrange column order in a sensible manner - categorical first, continuous last. Group common variables together.\n",
    "\n",
    "## More metadata after tidying\n",
    "* Find number of missing values per column\n",
    "* Number of rows and columns\n",
    "* Find the size of the dataset\n",
    "\n",
    "# Univariate vs Bivariate and Graphical vs Non-Graphical\n",
    "\n",
    "| Univariate             | Graphical                               | Non-Graphical                     | \n",
    "|-------------|-----------------------------------------|-----------------------------------|\n",
    "| Categorical | Bar char of frequencies (count/percent) | Contingency table (count/percent) |\n",
    "| Continuous  | Histogram/KDE, box, qqplot, fat tails  | central tendency -mean/median/mode, spread - variance, std, skew, kurt, IQR  |\n",
    "\n",
    "| Bivariate/multivariate            | Graphical                               | Non-Graphical                     | \n",
    "|-------------|-----------------------------------------|-----------------------------------|\n",
    "| Categorical vs Categorical | heat map, mosaic plot | Two-way Contingency table (count/percent) |\n",
    "| Continuous vs Continuous  | all pairwise scatterplots, kde, heatmaps |  all pairwise correlation/regression   |\n",
    "| Categorical vs Continuous  | [bar, violin, other seaborn plots](http://seaborn.pydata.org/tutorial/categorical.html)  | Summary statistics for each level |\n",
    "\n",
    "## Univariate Analysis\n",
    "* Analyze one variable at a time.\n",
    "\n",
    "### Categorical variables\n",
    "* There are less available options with categorical variables\n",
    "* Count the frequency of each variable\n",
    "* Low frequency strings might be outliers\n",
    "* You might want to relabel low frequency strings 'other'\n",
    "* Are there any categories that can be combined into one?\n",
    "* Find the number of unique values for each column\n",
    "* In pandas, change the data type to categorical (better when there aren't too many unique values)\n",
    "* Bar plots of frequency counts\n",
    "* String columns allow for feature engineering by extracting information withing the string, counting certain letters, finding the length of, etc... Feature engineering can be done later when modeling\n",
    "\n",
    "### Continuous variables\n",
    "* There are a lot more options for continuous variables\n",
    "* Use the five number summary - with **`.describe`**\n",
    "* Boxplots are great ways to find outliers\n",
    "* Use histograms and kernel density estimators to visualize the distribution.\n",
    "* Know the shape of the distribution\n",
    "* Think about making categorical variables out of continuous variables by cutting them into bins.\n",
    "\n",
    "### Use bootstrapping to get more 'samples'\n",
    "* Bootstrapping is done by resampling your data with replacement and gives you a 'new' random dataset\n",
    "* You can get estimates for the mean and variance of continuous columns this way.\n",
    "\n",
    "### Outliers in one dimension\n",
    "* Use your natural human ability to look at boxplots to find thresholds for what an outlier might be\n",
    "* Generate a new column of data that is 0/1 for outlier or not. This will quickly help you find them later.\n",
    "\n",
    "### Duplicated data\n",
    "* Lots of data gets accidentally duplicated. Check for duplicates or near duplicates of rows and columns\n",
    "* If any columns are calculated entirely by that of another column or columns (like with depth from the diamonds data), ensure the calculation holds. \n",
    "\n",
    "### Making new binary columns to label some finding\n",
    "* Just like it was described above to make a 0/1 column for outliers, you can do the same for any other finding\n",
    "* You can drop the duplicated rows or you can make a binary column labeling them. \n",
    "* Same for rows that do not have a correct calculation.\n",
    "\n",
    "## Bivariate and Multivariate EDA\n",
    "### Categorical vs Categorical\n",
    "* Create two way contingency table of frequency counts\n",
    "* Create a heat map\n",
    "* Find expected counts and possibly do a chi-squared test\n",
    "\n",
    "### Categorical vs Continuous\n",
    "* Use the seaborn categorical plots\n",
    "\n",
    "### Continuous vs Continuous\n",
    "* Plot all combinations of scatterplots\n",
    "* Use a hierarchical clustering plot to discover similar clusters within your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
