{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Time Series\n",
    "\n",
    "### Objectives\n",
    "* Make a web request and retrieve JSON data from the IEX trading API\n",
    "* Group by time with **`resample`**\n",
    "* Use offset aliases to determine amount of time\n",
    "* Create a DatetimeIndex and use it for easier resampling and subset selection\n",
    "* Use the **`rolling`** method to calculate moving window statistics\n",
    "\n",
    "## Introduction\n",
    "Broadly speaking, time series data are simply points of data gathered over time. Often, the time is evenly spaced between each data point. Pandas has good functionality with regards to manipulating dates, aggregating over different time periods, sampling different periods of time, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Data\n",
    "There are many tools available to get data stock market data. We will use the [IEX developer platform][1] which has an excellent an easy-to-use API to retrieve market data for free (up to 100 requests per second).\n",
    "\n",
    "### Using the requests library\n",
    "The **requests** third-party Python library helps retrieve data from another website. You simply pass the URL as a string to the **`get`** function. The returned object stores the data as a string in the **`text`** attribute. The requests library comes standard with the Anaconda distribution, so you should already have it. The requests library is one of the most popular third-party Python libraries.\n",
    "\n",
    "### Using the IEX API\n",
    "The IEX API is fairly straightforward to use and there are several examples that you can view to understand how it works. The base URL of the API is `https://api.iextrading.com/1.0` which can be [seen here in the docs][2]. If you scroll down from the last link, you will see how the API is used. Each **endpont** is documented. Let's use the [chart endpoint][3].\n",
    "\n",
    "We simply append **`/stock/{symbol}/chart/{range}`** to the base URL and put the stock symbol and range of data we want (without the curly braces) to retrieve historical stock price data. Go to the docs to view the available ranges.\n",
    "\n",
    "Let's retrieve the last 5 years of Amazon data (symbol AMZN) by passing our endpoint to the **`get`** function. A requests **`Response`** object is returned.\n",
    "\n",
    "[1]: https://iextrading.com/developer/\n",
    "[2]: https://iextrading.com/developer/docs/#endpoints\n",
    "[3]: https://iextrading.com/developer/docs/#chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://api.iextrading.com/1.0/stock/AMZN/chart/5y')\n",
    "type(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the `text`\n",
    "The response is captured as a Python string assigned to the **`text`** attribute. Let's print out the first 1,000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON objects\n",
    "Most APIs will respond with **JSON** data, a standardized format of data that is very similar to a Python dictionary with key-value pairs. This particular JSON data is returned as a list of dictionaries. We can usually read in an API response with the **`read_json`** pandas function which will attempt to convert the JSON text data to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = pd.read_json(req.text)\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify data types\n",
    "The **`read_json`** function will help choose the correct types for us. It's a good idea to verify that Pandas chose the correct data types with the **`dtype`** attribute. A common occurrence is for a column that looks like it contains numeric data to be actually kept as a string.\n",
    "\n",
    "Looking below, the data types seem to all be correct, save for **`label`**, which appears to be just a duplicate of the date column. We are good to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop some columns\n",
    "Let's drop the **`label`**, **`unadjustedVolumne`**, and **`vwap`** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn = amzn.drop(columns=['label', 'unadjustedVolume', 'vwap'])\n",
    "amzn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by time\n",
    "Pandas gives you the ability to group by a period of time. A concrete example can help here.\n",
    "\n",
    "### Find the average closing price of Amazon for every month\n",
    "If we are interested in finding the average closing price of Amazon for every month of data we have then we need to group by month and aggregate the closing price with the sum function.\n",
    "\n",
    "### Datetime column, amount of time, aggregating column, and aggregating method\n",
    "This procedure is very similar to how we grouped and aggregated columns in previous notebooks. The only difference is that, our **grouping column** will now be a datetime column with an additional specification for the amount of time.\n",
    "\n",
    "### Use the `resample` method\n",
    "Instead of the **`groupby`** method, we use a special method for grouping time together called **`resample`**. We must pass the **`resample`** method a time period as a string and the name of the datetime column. The rest of the process is the exact same as the **`groupby`** method. We call the **`agg`** method and pass it a dictionary mapping the **aggregating columns** to the **aggregating functions.\n",
    "\n",
    "### `resample` syntax\n",
    "The first parameter we pass to **`resample`** is the amount of time as a **string**. Here, we use **`'M'`** which refers to month. We also must specify which datetime column to use. Here, it is the **`date`** column. We then call **`agg`** as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('M', on='date').agg({'close': 'mean'}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use any number of aggregation functions\n",
    "Map the aggregating column to a list of aggregating functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('M', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offset Aliases\n",
    "All the possible strings that represent amounts of time are called [**offset aliases**](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases). They have been reprinted below:\n",
    "\n",
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"13%\" />\n",
    "<col width=\"87%\" />\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Alias</th>\n",
    "<th class=\"head\">Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td>B</td>\n",
    "<td>business day frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>C</td>\n",
    "<td>custom business day frequency (experimental)</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>D</td>\n",
    "<td>calendar day frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>W</td>\n",
    "<td>weekly frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>M</td>\n",
    "<td>month end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>BM</td>\n",
    "<td>business month end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>CBM</td>\n",
    "<td>custom business month end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>MS</td>\n",
    "<td>month start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>BMS</td>\n",
    "<td>business month start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>CBMS</td>\n",
    "<td>custom business month start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>Q</td>\n",
    "<td>quarter end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>BQ</td>\n",
    "<td>business quarter endfrequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>QS</td>\n",
    "<td>quarter start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>BQS</td>\n",
    "<td>business quarter start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>A</td>\n",
    "<td>year end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>BA</td>\n",
    "<td>business year end frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>AS</td>\n",
    "<td>year start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>BAS</td>\n",
    "<td>business year start frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>BH</td>\n",
    "<td>business hour frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>H</td>\n",
    "<td>hourly frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>T, min</td>\n",
    "<td>minutely frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>S</td>\n",
    "<td>secondly frequency</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>L, ms</td>\n",
    "<td>milliseconds</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>U, us</td>\n",
    "<td>microseconds</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>N</td>\n",
    "<td>nanoseconds</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('Q', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label with the beginning of the period\n",
    "Notice how the end date of both the month and quarter are used as index labels for the time periods. We can change the index labels so that they are from the beginning of the period by appending 'S' to our offset alias. This does not affect the amount of time, it only affects the label. \n",
    "\n",
    "Notice that using offset alias **`'QS'`** only changed the label to the beginning of the period. The actual data stayed the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('QS', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchored offsets\n",
    "By default, when grouping by week, Pandas chooses to end the week on Sunday. We say that it is **anchored** to Sunday. Let's verify this by grouping by week and taking the resulting index label and determining its weekday name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('W', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.to_datetime('2013-07-28')\n",
    "dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor by a different day\n",
    "You can anchor the week to any day you choose by appending a dash and then the first the letters of the day of the week. Let's anchor the week to Wednesday. [Anchored offsets][1] are available when grouping by quarter and year as well.\n",
    "\n",
    "[1]: http://pandas.pydata.org/pandas-docs/stable/timeseries.html#anchored-offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('W-WED', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer intervals of time with numbers within offset aliases\n",
    "We can actually add more details to our offset aliases by using a number to specify an amount of that particular offset alias. For instance, **`5M`** will group in 5 month intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('5M', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by every 22 weeks anchored to Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.resample('22W-THU', on='date').agg({'close': ['size', 'min', 'mean', 'max']}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the index as a datetime column\n",
    "The date column is a good choice of index since it uniquely identifies every row. Let's set it as the index and assign the result to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt = amzn.set_index('date')\n",
    "amzn_dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra functionality with a DatetimeIndex\n",
    "Whenever you set a datetime column as the index, your DataFrame gains a bit more extra functionality. The type of your index is now a **`DatetimeIndex`**. Let's verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(amzn_dt.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Subset selection with a DatetimeIndex\n",
    "One of the benefits is the easy subset selection that comes along with a DatetimeIndex. We can use date **strings** to select particular rows of our DataFrame. Let's select the row for May 7, 2014. \n",
    "\n",
    "Since we are selecting rows, it is best to use **`.loc`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.loc['2014-5-7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial date matching\n",
    "A much better feature is that we can select entire subsets of time with a partial date string. For instance, if we wanted to select the rows of just May 2014, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.loc['2014-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select entire years this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.loc['2014'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing ranges of dates\n",
    "It is possible to use slice notation to select an entire range of data. As usual, the endpoints are inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.loc['2014-6-9':'2014-6-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easier use of `resample` with a DatetimeIndex\n",
    "If you have a DatetimeIndex, then using the **`resample`** method will be slightly easier. You do not have to specify the date column with the **`on`** parameter as we did above. By default, Pandas will use the **index** to group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.resample('M').agg({'close':'mean'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Window Calculations\n",
    "Often in time series analysis, we would like to calculate a statistic over a continuous rolling window of time. With our a stock data, we might want to find the average closing price of the last 5 days. The **`rolling`** method helps accomplish this task.\n",
    "\n",
    "The **`rolling`** method works very similarly to the **`resample`** method. We pass it the offset alias of the length of our window and then aggregate as usual. The result will always be a DataFrame (or Series) with the same number of elements as the original.\n",
    "\n",
    "The following takes the mean of the last 5 day period at each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.rolling('5D').agg({'close': 'mean'}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "At each data point, the average of the last 5 days worth of data is found. Note, that this does not mean the window is always going to contain 5 values. It could contain more or less, depending on the dates in the time series. For instance, in the example above, the average calculated at **2013-07-31** contains only three data points (itself, **2013-07-30** and **2013-07-29**).\n",
    "\n",
    "We can include an additional aggregation function, **`count`**, to find verify the number of values in each window. We should be able to use **`size`** but there appears to be a bug in Pandas and its giving us an error. **`count`** works the same as there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.rolling('5D').agg({'close': ['mean', 'count']}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep window size the same with an integer\n",
    "Instead of using an offset alias, you can specify a specific window size with an integer. The following will always use the last 5 trading days (regardless of how many actual days pass) to determine an average.\n",
    "\n",
    "When using an integer for the window, the **`rolling`** method enforces that there must be that number of values present or else a missing value will be the result. This is what you are seeing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dt.rolling(5).agg({'close': 'mean'}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "Let's plot the 50-day min, mean, and max of the closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_stats = amzn_dt.rolling(50).agg({'close': ['min', 'mean', 'max']})\n",
    "rolling_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_stats = rolling_stats.dropna()\n",
    "rolling_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_stats.columns = ['Min', 'Mean', 'Max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib and choose a nice style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_stats.plot(figsize=(16, 4), style=['-', '--', '-'], title='AMZN Rolling Windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and Rolling Windows with a  Series - A bit easier\n",
    "Resampling and rolling window calculations can be done on Series that have DatetimeIndexes. The syntax becomes a bit easier since you don't have to specify an aggregating column. If you are only applying one aggregating function to the group, you can call it directly as method. With Series **`s`**, the syntax will look like this:\n",
    "\n",
    "```\n",
    ">>> s.resample('5D').sum()\n",
    "```\n",
    "\n",
    "We select the closing price as a Series below and proceed to call both the **`resample`** and **`rolling`** methods on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = amzn_dt['close']\n",
    "close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean over a two month period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.resample('2M').mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the rolling mean of the previous 5 trading days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.rolling(5).mean().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple aggregation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.resample('2M').agg(['min', 'mean', 'max']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is simpler when selecting the Series first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in stock data for Apple (AAPL) for the last 5 years. Set the date as the index and keep just the closing price and the volume columns.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">In which week did AAPL have the greatest number of its shares traded?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "<span  style=\"color:green; font-size:16px\">With help from the `diff` method, find the quarter containing the most number of up days.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "<span  style=\"color:green; font-size:16px\">Find the mean price per year along with the minimum and maximum volume. Have the label for each row be the first day of the year.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "<span  style=\"color:green; font-size:16px\">Execute the cell below exactly as it is to read in the employee dataset. Then use `to_datetime` to convert the hire and job date columns into datetimes.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this as is\n",
    "emp = pd.read_csv('../data/employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "<span  style=\"color:green; font-size:16px\">Execute the cell below exactly as it is to read in the employee dataset. Then use `to_datetime` to convert the hire and job date columns into datetimes.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "<span  style=\"color:green; font-size:16px\">Without putting `hire_date` into the index, find the mean salary based on `hire_date` over 5 year periods. Also return the number of salaries used in the mean calculation for each period.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "<span  style=\"color:green; font-size:16px\">Attempt to take a rolling average on salary using a 30 day time span on hire date. Does the error message make sense?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "<span  style=\"color:green; font-size:16px\">Set hire date as the index and then select the salary column as a Series. Sort the Series by date and drop the missing values. Now select a subset that only has hire dates from 1990 onwards. Then find a 1,000 day rolling average. Finally make a call to the `plot` method. Make sure you inline matplotlib if you did not do it earlier.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10\n",
    "<span  style=\"color:green; font-size:16px\">Can you do problem 9 in one line of code? Chain each method on a separate line. (You should probably not do this in real code as it will be messy, but it is possible)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
