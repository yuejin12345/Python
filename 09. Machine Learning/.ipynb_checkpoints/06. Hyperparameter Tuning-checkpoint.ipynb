{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning\n",
    "All the machine learning models contain hyperparameters than you can tune (as if they were knobs on a guitar). By changing the hyperparameters, the model be specified at a different setting. Different datasets require different hyperparameter settings for optimal performance. For instance, a [decision tree classifier][1] has many hyper-parameters, some of which are:\n",
    "\n",
    "* **criterion** : Measures quality of the split - default is mean squared error, can also be mean absolute error\n",
    "* **max_depth** : The maximum depth of the tree. Default is to continue making splits until node is pure\n",
    "* **min_samples_split** : The minimum number of samples required to split an internal node - default is 2\n",
    "* **min_samples_leaf** : The minimum number of samples required to be at a leaf node. Default is 1\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters vs Parameters\n",
    "Hyperparameters are all the knobs that you have control over. You set them during **instantiation**. They do NOT change during training. Many of these models have \"normal\" parameters that are fit during **training**. These parameters are completely different than hyperparameters. The algorithm will find the optimal value of these parameters during training based on the evaluation metric that it uses. For instance, in a linear regression, the normal parameters are the slope and intercept.\n",
    "\n",
    "Hyperparameters never change after you have instantiated your model. In a decision tree, a hyperparameter such as **`max_depth`** dictates the maximum depth of the tree. The algorithm must stop growing the tree when it reaches that depth. The location of where and how the splits take place is learned through the model and can be thought of as a normal parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "Previously, we saw a decision tree severely overfit the data by having a test score significantly worse than a training score. Let's recreate this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv('../data/heart.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "X = heart[['max_hr', 'rest_bp']].values\n",
    "y = heart['disease'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X, y)\n",
    "dtc.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtc, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the decision tree\n",
    "Scikit-learn returns the tree object to us as the **`tree_`** attribute. Let's assign it to its own variable and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dtc.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.node_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change hyperparameters to reduce overfitting\n",
    "We can reduce the amount of overfitting by specifying different hyperparameters during model instantiation. For instance, we specify a `max_depth` of 7 below which increases our cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=7)\n",
    "scores = cross_val_score(dtc, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "<span  style=\"color:green; font-size:16px\">Continue to tune the decision tree by changing the `max_depth` parameter. Find the value of `max_depth` that achieves the highest score.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "<span  style=\"color:green; font-size:16px\">Make a plot of `max_depth` vs cross validation score.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
